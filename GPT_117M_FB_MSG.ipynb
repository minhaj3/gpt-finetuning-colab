{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT 117M FB-MSG",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhaj3/gpt-finetuning-colab/blob/master/GPT_117M_FB_MSG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE_fFgQ8a_Dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etM-i8RwbcTH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "fb7ff9a1-1d6e-4c9e-9331-4347080d2d59"
      },
      "source": [
        "!git clone -b small https://github.com/Tenoke/gpt-2.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 244, done.\u001b[K\n",
            "remote: Total 244 (delta 0), reused 0 (delta 0), pack-reused 244\u001b[K\n",
            "Receiving objects: 100% (244/244), 4.39 MiB | 14.68 MiB/s, done.\n",
            "Resolving deltas: 100% (125/125), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVTyGrhsbdep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a181b1a4-8868-4f37-a7da-47cd27fe8fa0"
      },
      "source": [
        "cd gpt-2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypGcyhOkd5qp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "cfe9df88-132a-4393-bbd8-9fcffdc24669"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t   fb-cleaned-medha.txt  LICENSE\t   samples\n",
            "Dockerfile.cpu\t   fb-cleaned.txt\t messages\t   src\n",
            "Dockerfile.gpu\t   fb-cleaned.txt.npz\t models\t\t   train.py\n",
            "download_model.sh  fb-json.zip\t\t README.md\n",
            "encode.py\t   gpt-2-samples\t requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDLUxywodvFN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "cb225661-ab97-45da-8290-3202adbb2d9b"
      },
      "source": [
        "!cat download_model.sh"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#!/bin/sh\n",
            "\n",
            "if [ \"$#\" -ne 1 ]; then\n",
            "    echo \"You must enter the model name as a parameter, e.g.: sh download_model.sh 117M\"\n",
            "    exit 1\n",
            "fi\n",
            "\n",
            "model=$1\n",
            "\n",
            "mkdir -p models/$model\n",
            "\n",
            "# TODO: gsutil rsync -r gs://gpt-2/models/ models/\n",
            "for filename in checkpoint encoder.json hparams.json model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.meta vocab.bpe; do\n",
            "  fetch=$model/$filename\n",
            "  echo \"Fetching $fetch\"\n",
            "  curl --output models/$fetch https://storage.googleapis.com/gpt-2/models/$fetch\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azu6KCOHbhIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "0a7e34d2-77f2-4243-b372-f18c80a8e171"
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire>=0.1.3 (from -r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.8MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5 (from -r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Building wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103527 sha256=8244b71ca2f20a9bec89432042005fc51837616254c991a271005738c8726b83\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp36-cp36m-linux_x86_64.whl size=533170 sha256=40850c3bdc2f363383a4865b6d51c068138032c98448db233a85b8c0e5b4acc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built fire regex\n",
            "Installing collected packages: fire, regex\n",
            "Successfully installed fire-0.2.1 regex-2017.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecmuIWxFgFBz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "3d69ef7f-7252-4e8c-ae17-9d5c738875c8"
      },
      "source": [
        "!sh download_model.sh 117M"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching 117M/checkpoint\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100    77  100    77    0     0    726      0 --:--:-- --:--:-- --:--:--   733\n",
            "Fetching 117M/encoder.json\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 1017k  100 1017k    0     0  8208k      0 --:--:-- --:--:-- --:--:-- 8208k\n",
            "Fetching 117M/hparams.json\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100    90  100    90    0     0   1267      0 --:--:-- --:--:-- --:--:--  1267\n",
            "Fetching 117M/model.ckpt.data-00000-of-00001\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  474M  100  474M    0     0   159M      0  0:00:02  0:00:02 --:--:--  159M\n",
            "Fetching 117M/model.ckpt.index\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5215  100  5215    0     0  66012      0 --:--:-- --:--:-- --:--:-- 66012\n",
            "Fetching 117M/model.ckpt.meta\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  460k  100  460k    0     0  5288k      0 --:--:-- --:--:-- --:--:-- 5288k\n",
            "Fetching 117M/vocab.bpe\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  445k  100  445k    0     0  3564k      0 --:--:-- --:--:-- --:--:-- 3564k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmj-M0Iobv3L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "7ddafebd-0f3f-4dae-d41e-9571f5af9acc"
      },
      "source": [
        "#!curl 'https://bigzipfiles.facebook.com/p/dl/download/file.php?r=100000045203418&t=100000045203418&j=11&i=2423522277659255&ext=1552347802&hash=AaDXnDMervVmbTPV' -H 'authority: bigzipfiles.facebook.com' -H 'upgrade-insecure-requests: 1' -H 'dnt: 1' -H 'user-agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.121 Safari/537.36' -H 'accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8' -H 'referer: https://www.facebook.com/' -H 'accept-encoding: gzip, deflate, br' -H 'accept-language: en-GB,en;q=0.9,bg-BG;q=0.8,bg;q=0.7,en-US;q=0.6' -H 'cookie: datr=qi5tXEI5YtkypxAdISqJGNZd; sb=qi5tXJPGdhJhbt5N04dUGcUv; c_user=100000045203418; xs=29%3AgDb81L_oJkC4Kg%3A2%3A1550659246%3A4402%3A5224; pl=n; dpr=0.8999999761581421; spin=r.1000481805_b.trunk_t.1552342837_s.1_v.2_; fr=1BXrWEDVIeChp7NLC.AWXvyWCWdyCZAdTM2bSw40pj8-E.BcbS6q.Hm.AAA.0.0.BchuAL.AWWf6I2i; presence=EDvF3EtimeF1552346587EuserFA21BB45203418A2EstateFDsb2F1552344421952EatF1552345159684Et3F_5bDiFA2user_3a1B00305017170A2EoF1EfF1CAcDiFA2user_3a1B01308116906A2EoF2EfF3CAcDiFA2user_3a1B08124067081A2EoF3EfF2C_5dEutc3F1552345156737G552346587474CEchFDp_5f1BB45203418F1CC; act=1552346589369%2F2; wd=901x697; pnl_data2=eyJhIjoib25hZnRlcmxvYWQiLCJjIjoiWERZSVJlcXVlc3RDb250cm9sbGVyIiwiYiI6ZmFsc2UsImQiOiIvcC9kbC9kb3dubG9hZC9maWxlLnBocCIsImUiOltdfQ%3D%3D' --compressed --output fb-json.zip\n",
        "!curl 'https://bigzipfiles.facebook.com/p/dl/download/file.php?r=100002213815538&t=100002213815538&j=11&i=2511412695609166&f=2511419428941826&ext=1571498646&hash=AaBdbiByc0GNk936' -H 'User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:69.0) Gecko/20100101 Firefox/69.0' -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' -H 'Accept-Language: en-US,en;q=0.5' --compressed -H 'Referer: https://www.facebook.com/' -H 'DNT: 1' -H 'Connection: keep-alive' -H 'Cookie: fr=1kqjDg4tKBuaeNIlM.AWXtXHVfhF0iX8j3iL5TzspBuT8.BdqvWe.ka.AAA.0.0.Bdqx_S.AWUV6qw2; wd=1525x429; datr=nvWqXTbYKGPWUb-Qml8vXa28; sb=tfWqXYj5C6mdrim5_8_3PwdR; locale=en_GB; c_user=100002213815538; xs=28%3AZjeg_deLGi5x7Q%3A2%3A1571485372%3A12391%3A4201; spin=r.1001317877_b.trunk_t.1571485374_s.1_v.2_; dpr=0.8955223880597015; act=1571496210395%2F4; presence=EDvF3EtimeF1571495938EuserFA21B02213815538A2EstateFDutF1571495938462CEchFDp_5f1B02213815538F1CC; pnl_data2=eyJhIjoib25hZnRlcmxvYWQiLCJjIjoiWERZSVJlcXVlc3RDb250cm9sbGVyIiwiYiI6ZmFsc2UsImQiOiIvcC9kbC9kb3dubG9hZC9maWxlLnBocCIsImUiOltdfQ%3D%3D' -H 'Upgrade-Insecure-Requests: 1' -H 'TE: Trailers'  --compressed --output fb-json.zip"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 39.7M  100 39.7M    0     0  22.0M      0  0:00:01  0:00:01 --:--:-- 22.0M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVx0O2rsdMak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip fb-json.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FRqHPeigLLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l -h "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp7wgFSKdrBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3666df9-e90c-4c80-9073-b2222adceed7"
      },
      "source": [
        "files = []\n",
        "for p, d, f in os.walk('messages/inbox'):\n",
        "    for file in f:\n",
        "        if file.endswith('message_1.json'):\n",
        "            files.append(f'{p}/{file}')\n",
        "\n",
        "len(files)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fZB1hVWdsO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fix_encoding(s):\n",
        "  return re.sub('[\\xc2-\\xf4][\\x80-\\xbf]+',lambda m: m.group(0).encode('latin1').decode('utf8'),s)\n",
        "\n",
        "def find_cyrilic(s):\n",
        "    return len(re.findall('(?i)[А-ЯЁ]', s)) > 0\n",
        "\n",
        "def test_mostly_cyrilic(messages):\n",
        "  i = 0\n",
        "  check_n = min(250, len(messages))\n",
        "  for msg in random.sample(messages, check_n):\n",
        "    try:\n",
        "      i +=find_cyrilic(fix_encoding(msg['content'])) or find_cyrilic(fix_encoding(msg['sender_name']))\n",
        "    except KeyError:\n",
        "      check_n -=1\n",
        "  return i > check_n/5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgpW_adCinm4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffab40ad-550e-4158-9739-c993697aebb0"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lssDwjCqeUvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "text_corpus = ''\n",
        "banned_names = ()\n",
        "for file in files:\n",
        "  with open(file, 'r') as f:\n",
        "      try:\n",
        "        msgs = json.load(f)['messages']\n",
        "        msgs.reverse()\n",
        "      except:\n",
        "        pass\n",
        "      else:\n",
        "        if not test_mostly_cyrilic(msgs) and not any(bn in file for bn in banned_names):\n",
        "          for msg in msgs:\n",
        "            try:\n",
        "              content = fix_encoding(msg['content'])\n",
        "              to_add  = f\"({msg['timestamp_ms']}) {msg['sender_name']}: {content}\\n\"\n",
        "              if not find_cyrilic(to_add):\n",
        "                text_corpus += to_add\n",
        "            except KeyError:\n",
        "              pass\n",
        "          print(file)\n",
        "\n",
        "          text_corpus += '\\n\\n'\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzivJRABemEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('fb-cleaned.txt', 'w') as f:\n",
        "  f.write(text_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2-MfFxgemo4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4931bc78-fe57-4499-d0ed-44c35108c234"
      },
      "source": [
        "!du -h fb-cleaned.txt"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0M\tfb-cleaned.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nhops-Gi7s9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "outputId": "a7ad12d6-07f2-410d-a7d6-5e7d1ea49497"
      },
      "source": [
        "!cat encode.py"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#!/usr/bin/env python3\n",
            "# Usage:\n",
            "#  PYTHONPATH=src ./encode.py <file|directory|glob> /path/to/output.npz\n",
            "#  PYTHONPATH=src ./train --dataset /path/to/output.npz\n",
            "\n",
            "import fire\n",
            "import json\n",
            "import os\n",
            "import numpy as np\n",
            "import tensorflow as tf\n",
            "import random\n",
            "import time\n",
            "import tqdm\n",
            "import glob\n",
            "\n",
            "import encoder\n",
            "\n",
            "\n",
            "def load_dataset(enc, path):\n",
            "    paths = []\n",
            "    if os.path.isfile(path):\n",
            "        # Simple file\n",
            "        paths.append(path)\n",
            "    elif os.path.isdir(path):\n",
            "        # Directory\n",
            "        for (dirpath, _, fnames) in os.walk(path):\n",
            "            for fname in fnames:\n",
            "                paths.append(os.path.join(dirpath, fname))\n",
            "    else:\n",
            "        # Assume glob\n",
            "        paths = glob.glob(path)\n",
            "\n",
            "    token_chunks = []\n",
            "    for path in tqdm.tqdm(paths):\n",
            "        with open(path, 'r') as fp:\n",
            "            raw_text = fp.read()\n",
            "        tokens = np.stack(enc.encode(raw_text))\n",
            "        token_chunks.append(tokens)\n",
            "    return token_chunks\n",
            "\n",
            "\n",
            "def encode_main(in_text, out_npz, model_name='117M'):\n",
            "    enc = encoder.get_encoder(model_name)\n",
            "    print('Reading files')\n",
            "    chunks = load_dataset(enc, in_text)\n",
            "    print('Writing', out_npz)\n",
            "    np.savez_compressed(out_npz, *chunks)\n",
            "\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    fire.Fire(encode_main)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzHsNeMNenxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e30756dc-4c86-4c5d-f1f5-5f9ab4826b5c"
      },
      "source": [
        "!PYTHONPATH=src ./encode.py --in-text fb-cleaned-junaid.txt --out-npz fb-cleaned.txt.npz"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading files\n",
            "100% 1/1 [00:03<00:00,  3.81s/it]\n",
            "Writing fb-cleaned.txt.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbBJ6JoufBGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!PYTHONPATH=src ./train.py --dataset fb-cleaned.txt.npz --sample_every=250 --learning_rate=0.0001 --stop_after=251\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EykQ2j4bfB0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!PYTHONPATH=src ./train.py --dataset fb-cleaned.txt.npz --sample_every=250 --learning_rate=0.001 --stop_after=751\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyduXYIKfCU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!PYTHONPATH=src ./train.py --dataset fb-cleaned.txt.npz --sample_every=250 --learning_rate=0.0001 --beta=0.95 --stop_after=1251"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNXhOM22fNHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/117M/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2csc2bZHfrXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 src/generate_unconditional_samples.py --top_k 40 --temperature 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIfrihP2tfow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --top_k 40 --temperature 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhD-xC4IsPiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_specific_file(person, files=files):\n",
        "  text_corpus = ''\n",
        "  for file in files:\n",
        "    if person in file:\n",
        "      print(file)\n",
        "      with open(file, 'r') as f:\n",
        "          try:\n",
        "            msgs = json.load(f)['messages']\n",
        "            msgs.reverse()\n",
        "          except:\n",
        "            pass\n",
        "          else:\n",
        "            for msg in msgs:\n",
        "              try:\n",
        "                content = fix_encoding(msg['content'])\n",
        "                to_add  = f\"({msg['timestamp_ms']}) {msg['sender_name']}: {content}\\n\"\n",
        "                if not find_cyrilic(to_add):\n",
        "                  text_corpus += to_add\n",
        "              except KeyError:\n",
        "                pass\n",
        "\n",
        "              text_corpus += '\\n\\n'\n",
        "      with open(f'fb-cleaned-{person}.txt', 'w') as f:\n",
        "        f.write(text_corpus)\n",
        "        return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfqvbibAubHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_specific_file('junaid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCcXPhSuu7Gd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9740bbc5-50eb-4f78-b9c7-f1c13f6d978d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t   fb-cleaned-medha.txt  LICENSE\t   samples\n",
            "Dockerfile.cpu\t   fb-cleaned.txt\t messages\t   src\n",
            "Dockerfile.gpu\t   fb-cleaned.txt.npz\t models\t\t   train.py\n",
            "download_model.sh  fb-json.zip\t\t README.md\n",
            "encode.py\t   gpt-2-samples\t requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gkEdFbcu9Y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}